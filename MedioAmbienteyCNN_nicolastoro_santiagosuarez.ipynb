{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaC2GeHktrEK"
      },
      "source": [
        "# ESCUELA COLOMBIANA DE INGENIERÍA:\n",
        "# PRINCIPIOS Y TECNOLOGÍAS IA 2025-2\n",
        "## CLASIFICACIÓN INTELIGENTE DE RESIDUOS SÓLIDOS MEDIANTE REDES NEURONALES CONVOLUCIONALES\n",
        "## PROYECTO\n",
        "\n",
        "**OBJETIVO GENERAL**\n",
        "\n",
        "Desarrollar un agente supervisado de clasificación automática de residuos sólidos mediante una red neuronal convolucional (CNN) que permita diferenciar materiales orgánicos, inorgánicos y aprovehcables, contribuyendo a la gestión ambiental sostenible en la ciudad de Bogotá.\n",
        "\n",
        "**OBJETIVOS**\n",
        "\n",
        "1. Diseña red convolucional (CNN).\n",
        "2. Implementar red convolucional (CNN).\n",
        "3. Evaluar su desempeño mediante métricas apropiadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nliCNAA3tQbp",
        "outputId": "0c8c2d5f-db4a-4930-c1d1-f34430a1d922"
      },
      "outputs": [],
      "source": [
        "# ---\n",
        "%pip install -q scikit-learn matplotlib seaborn\n",
        "\n",
        "%pip install kaggle\n",
        "\n",
        "%pip install --quiet kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdk070MfIz9S"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "\n",
        "KAGGLE_DATASET_ID = \"phenomsg/waste-classification\"\n",
        "path_to_downloaded_dataset = kagglehub.dataset_download(KAGGLE_DATASET_ID)\n",
        "print(\"Path to downloaded dataset files:\", path_to_downloaded_dataset)\n",
        "\n",
        "DATA_DIR = path_to_downloaded_dataset\n",
        "\n",
        "print(f\"Inspecting contents of DATA_DIR: {DATA_DIR}\")\n",
        "image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.bmp')\n",
        "found_non_image_files = []\n",
        "all_image_paths = []\n",
        "all_image_labels = []\n",
        "\n",
        "class_names = sorted([d.name for d in os.scandir(DATA_DIR) if d.is_dir()])\n",
        "class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
        "\n",
        "for root, _, files in os.walk(DATA_DIR):\n",
        "    relative_path = os.path.relpath(root, DATA_DIR)\n",
        "    class_name = None\n",
        "    if relative_path != '.':\n",
        "        parts = relative_path.split(os.sep)\n",
        "        if len(parts) >= 1:\n",
        "            class_name = parts[0]\n",
        "\n",
        "    if class_name not in class_names:\n",
        "        continue\n",
        "\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "\n",
        "        if os.path.getsize(file_path) == 0:\n",
        "            found_non_image_files.append(file_path)\n",
        "            continue\n",
        "\n",
        "        ext = os.path.splitext(file_path)[1].lower()\n",
        "        if ext not in image_extensions:\n",
        "            found_non_image_files.append(file_path)\n",
        "        else:\n",
        "            all_image_paths.append(file_path)\n",
        "            all_image_labels.append(class_to_idx[class_name])\n",
        "\n",
        "if found_non_image_files:\n",
        "    print(f\"Total non-image/corrupted files found: {len(found_non_image_files)}.\")\n",
        "else:\n",
        "    print(\"No unusual files found.\")\n",
        "\n",
        "NUM_CLASSES = len(class_names)\n",
        "print(\"Clases:\", class_names)\n",
        "print(f\"Found {len(all_image_paths)} valid images.\")\n",
        "\n",
        "SEED = 42\n",
        "combined = list(zip(all_image_paths, all_image_labels))\n",
        "np.random.seed(SEED)\n",
        "np.random.shuffle(combined)\n",
        "all_image_paths, all_image_labels = zip(*combined)\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "TRAIN_SPLIT_RATIO = 0.8\n",
        "VAL_SPLIT_RATIO = 0.1\n",
        "TEST_SPLIT_RATIO = 0.1\n",
        "\n",
        "total_images = len(all_image_paths)\n",
        "train_size = int(TRAIN_SPLIT_RATIO * total_images)\n",
        "val_size = int(VAL_SPLIT_RATIO * total_images)\n",
        "test_size = total_images - train_size - val_size\n",
        "\n",
        "train_paths = all_image_paths[:train_size]\n",
        "train_labels = all_image_labels[:train_size]\n",
        "\n",
        "val_paths = all_image_paths[train_size : train_size + val_size]\n",
        "val_labels = all_image_labels[train_size : train_size + val_size]\n",
        "\n",
        "test_paths = all_image_paths[train_size + val_size : train_size + val_size + test_size]\n",
        "test_labels = all_image_labels[train_size + val_size : train_size + val_size + test_size]\n",
        "\n",
        "print(f\"Dataset sizes: Train={len(train_paths)}, Val={len(val_paths)}, Test={len(test_paths)}\")\n",
        "\n",
        "def _decode_and_resize(image_path_tensor):\n",
        "    image_path_str = image_path_tensor.numpy().decode('utf-8')\n",
        "    try:\n",
        "        img_raw = tf.io.read_file(image_path_str)\n",
        "        img = tf.image.decode_image(img_raw, channels=3, expand_animations=False)\n",
        "        if img.shape.rank is None or img.shape.rank < 3:\n",
        "            raise ValueError()\n",
        "        img = tf.image.resize(img, IMG_SIZE)\n",
        "        img = tf.cast(img, tf.float32)\n",
        "        return img\n",
        "    except:\n",
        "        return tf.zeros(IMG_SIZE + (3,), dtype=tf.float32)\n",
        "\n",
        "def preprocess_image(image_path, label):\n",
        "    img = tf.py_function(func=_decode_and_resize, inp=[image_path], Tout=tf.float32)\n",
        "    img.set_shape(IMG_SIZE + (3,))\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return img, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((list(train_paths), list(train_labels))) \\\n",
        "             .map(preprocess_image, num_parallel_calls=AUTOTUNE) \\\n",
        "             .shuffle(1000) \\\n",
        "             .batch(BATCH_SIZE) \\\n",
        "             .prefetch(AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((list(val_paths), list(val_labels))) \\\n",
        "           .map(preprocess_image, num_parallel_calls=AUTOTUNE) \\\n",
        "           .batch(BATCH_SIZE) \\\n",
        "           .prefetch(AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((list(test_paths), list(test_labels))) \\\n",
        "            .map(preprocess_image, num_parallel_calls=AUTOTUNE) \\\n",
        "            .batch(BATCH_SIZE) \\\n",
        "            .prefetch(AUTOTUNE)\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.06),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "])\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
        "x = data_augmentation(inputs)\n",
        "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
        "earlystop_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)\n",
        "reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "history1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint_cb, earlystop_cb, reduce_lr_cb, tensorboard_cb]\n",
        ")\n",
        "\n",
        "base_model.trainable = True\n",
        "fine_tune_at = 50\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=20,\n",
        "    callbacks=[checkpoint_cb, earlystop_cb, reduce_lr_cb, tensorboard_cb]\n",
        ")\n",
        "\n",
        "model.load_weights(\"best_model.h5\")\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(\"Test accuracy:\", test_acc, \"Test loss:\", test_loss)\n",
        "\n",
        "y_true_list = []\n",
        "for images, labels in test_ds:\n",
        "    y_true_list.append(labels.numpy())\n",
        "y_true = np.concatenate(y_true_list, axis=0)\n",
        "y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "preds = model.predict(test_ds)\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "def plot_confusion_matrix(cm, classes):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('True')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plot_confusion_matrix(cm, class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72wIx3c3P2xj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def predict_url(image_url):\n",
        "    try:\n",
        "        path = tf.keras.utils.get_file(origin=image_url)\n",
        "        \n",
        "        img = keras.utils.load_img(path, target_size=(500, 500))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        img_array = keras.utils.img_to_array(img)\n",
        "        img_array = tf.expand_dims(img_array, 0) \n",
        "\n",
        "        img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
        "\n",
        "        predictions = model.predict(img_array)\n",
        "        score = tf.nn.softmax(predictions[0])\n",
        "        \n",
        "        predicted_class = class_names[np.argmax(score)]\n",
        "        confidence = 100 * np.max(score)\n",
        "        \n",
        "        print(f\" Predicción: {predicted_class}\")\n",
        "        print(f\" Confianza: {confidence:.2f}%\")\n",
        "        \n",
        "        print(\"\\n--- Probabilidades por clase ---\")\n",
        "        for i, name in enumerate(class_names):\n",
        "            print(f\"{name}: {100 * predictions[0][i]:.2f}%\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\" Error al cargar la imagen: {e}\")\n",
        "\n",
        "\n",
        "url = \"\" \n",
        "\n",
        "predict_url(url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
